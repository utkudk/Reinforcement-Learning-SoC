{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Monte Carlo ES\n",
    "\n",
    "- Here you are given an executable that represents the Markov Decision Process. The executable is named [```MDP```](./MDP).\n",
    "\n",
    "- You can query the number of states and actions of the MDP with ```./MDP states``` and ```./MDP actions```. The discount factor of the MDP can be obtained with ```./MDP gamma```.\n",
    "\n",
    "- To start interacting with the MDP, run ```./MDP <starting state>```. At every iteration, the executable will display the current state and current return of the MDP, and ask you to choose an action, after which it will give a reward, and transition to a new state.\n",
    "\n",
    "- You must implement the Monte Carlo ES algorithm that learns the optimal policy of the MDP by simulating episodes with exploring starts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloES:\n",
    "    '''\n",
    "    Implement your algorithm here, and define appropriate helper classes as required.\n",
    "    Have a look at the sample solution for Week 1 that was uploaded to know the expected code structure.\n",
    "    '''\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
